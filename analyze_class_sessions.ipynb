{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"config.env\")\n",
    "\n",
    "DATA_FOLDER = os.getenv(\"DATA_FOLDER\")\n",
    "OUTPUT_FOLDER = os.getenv(\"OUTPUT_FOLDER\")\n",
    "SAMPLE_FOLDER = os.getenv(\"SAMPLE_FOLDER\")\n",
    "CLASS_SESSIONS_FOLDER = os.getenv(\"CLASS_SESSIONS_FOLDER\")\n",
    "try:\n",
    "    BEACON_RATE = float(os.getenv(\"BEACON_RATE\"))\n",
    "except ValueError:\n",
    "    print(\"Invalid float value in BEACON_RATE env variable.\")\n",
    "    BEACON_RATE = 0.1024\n",
    "if not os.path.exists(CLASS_SESSIONS_FOLDER):   \n",
    "    os.makedirs(CLASS_SESSIONS_FOLDER)\n",
    "\n",
    "#log to a file and print to terminal\n",
    "# Open logging file\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "log_filename = f\"{OUTPUT_FOLDER}/analyze_class_sessions_log_{timestamp}.txt\"\n",
    "log_file = open(log_filename, \"a\")# Open file in append mode\n",
    "def log_and_print(message):\n",
    "    print(message)  # Print to terminal is too noisy\n",
    "    log_file.write(message + \"\\n\")  # Write to file\n",
    "\n",
    "\n",
    "log_and_print(f\"Class session analysis started on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# read in the sample for class sessions as a basis for all information for class sessions\n",
    "class_sessions_df = pd.read_parquet(f\"{SAMPLE_FOLDER}/sample_classes.parquet\")\n",
    "sample_aps_df = pd.read_parquet(f\"{SAMPLE_FOLDER}/sample_aps.parquet\")\n",
    "sample_classrooms_df = pd.read_parquet(f\"{SAMPLE_FOLDER}/sample_classrooms.parquet\")\n",
    "\n",
    "#Adding additional columns to the DataFrame\n",
    "# Ensure string columns use Pandas' dedicated string dtype\n",
    "class_sessions_df['group'] = pd.Series(dtype=\"string\")\n",
    "\n",
    "# Set numerical columns with nullable integer dtype (Int64)\n",
    "class_sessions_df['number_aps'] = pd.Series(dtype=\"Int64\")\n",
    "class_sessions_df['number_radios'] = pd.Series(dtype=\"Int64\")\n",
    "class_sessions_df['number_beacons'] = pd.Series(dtype=\"Int64\")\n",
    "class_sessions_df['max_stations'] = pd.Series(dtype=\"Int64\")\n",
    "class_sessions_df['max_cu'] = pd.Series(dtype=\"Int64\")\n",
    "class_sessions_df['average_cu'] = pd.Series(dtype=\"Float64\")\n",
    "class_sessions_df['median_cu'] = pd.Series(dtype=\"Float64\")\n",
    "class_sessions_df['stations_enrolled'] = pd.Series(dtype=\"Float64\")\n",
    "\n",
    "# Compute class_duration in SECONDS (float since it involves time differences)\n",
    "class_sessions_df['class_duration'] = (class_sessions_df['end_time'] - class_sessions_df['start_time']).dt.total_seconds().astype(\"Float64\")\n",
    "\n",
    "# Ensure duration_75 and duration_50 are also float types but nullable\n",
    "class_sessions_df['duration_75'] = pd.Series(dtype=\"Float64\")\n",
    "class_sessions_df['duration_50'] = pd.Series(dtype=\"Float64\")\n",
    "class_sessions_df['max_streak_75'] = pd.Series(dtype=\"Float64\")\n",
    "class_sessions_df['max_streak_50'] = pd.Series(dtype=\"Float64\")\n",
    "class_sessions_df['sum_scount_75'] = pd.Series(dtype=\"Float64\")\n",
    "class_sessions_df['sum_scount_50'] = pd.Series(dtype=\"Float64\")\n",
    "\n",
    "# Count occurrences of each Building-Room in sample_aps_df\n",
    "aps_count = sample_aps_df['Building-Room'].value_counts()\n",
    "\n",
    "# Map these counts to the number_aps column in class_sessions_df\n",
    "class_sessions_df['number_aps'] = class_sessions_df['location'].map(aps_count).astype(\"Int64\")\n",
    "\n",
    "\n",
    "#Group A, B, and C are from the sample selection based on classroom size\n",
    "# Create a mapping from sample_classrooms_df: Location -> Group\n",
    "location_to_group = sample_classrooms_df.set_index('Location')['Group']\n",
    "\n",
    "# Map the Group values to class_sessions_df based on location\n",
    "class_sessions_df['group'] = class_sessions_df['location'].map(location_to_group).astype(\"string\")\n",
    "\n",
    "\n",
    "# calculate metrics for each class session\n",
    "all_class_beacons_processed_df = pd.read_parquet(f\"{DATA_FOLDER}/all_class_beacons_processed.parquet\")\n",
    "\n",
    "BEACON_WINDOW_SEC = BEACON_RATE \n",
    "CU_THRESHOLDS = {'75': 191, '50': 127}\n",
    "\n",
    "print(\"Calculating metrics for each class session...\")\n",
    "for idx, session in tqdm(class_sessions_df.iterrows(), total=len(class_sessions_df)):\n",
    "    start = session['start_time']\n",
    "    end = session['end_time']\n",
    "    location = session['location']\n",
    "\n",
    "    mask = (\n",
    "        (all_class_beacons_processed_df['aruba_erm.time'] >= start) &\n",
    "        (all_class_beacons_processed_df['aruba_erm.time'] <= end) &\n",
    "        (all_class_beacons_processed_df['location'] == location)\n",
    "    )\n",
    "    filtered = all_class_beacons_processed_df[mask].copy()\n",
    "    filtered.sort_values('aruba_erm.time', inplace=True)\n",
    "\n",
    "    number_beacons = len(filtered)\n",
    "\n",
    "    if number_beacons > 0:\n",
    "        max_scount = filtered['room_scount'].max()\n",
    "        cu_values = filtered['wlan.qbss.cu'].dropna()\n",
    "        max_cu = cu_values.max()\n",
    "        avg_cu = cu_values.mean()\n",
    "        median_cu = cu_values.median()\n",
    "\n",
    "        # Time binning for duration + streaks\n",
    "        time_range = pd.date_range(start, end, freq=f\"{BEACON_WINDOW_SEC}s\")\n",
    "        duration = {'75': 0, '50': 0}\n",
    "        current_streak = {'75': 0, '50': 0}\n",
    "        max_streak = {'75': 0, '50': 0}\n",
    "\n",
    "        for i in range(len(time_range) - 1):\n",
    "            t_start = time_range[i]\n",
    "            t_end = time_range[i + 1]\n",
    "\n",
    "            bin_slice = filtered[\n",
    "                (filtered['aruba_erm.time'] >= t_start) & (filtered['aruba_erm.time'] < t_end)\n",
    "            ]\n",
    "\n",
    "            if not bin_slice.empty:\n",
    "                for level, threshold in CU_THRESHOLDS.items():\n",
    "                    if (bin_slice['wlan.qbss.cu'] > threshold).any():\n",
    "                        duration[level] += BEACON_WINDOW_SEC\n",
    "                        current_streak[level] += BEACON_WINDOW_SEC\n",
    "                        max_streak[level] = max(max_streak[level], current_streak[level])\n",
    "                    else:\n",
    "                        current_streak[level] = 0\n",
    "\n",
    "        # Scount sums for each threshold based on unique wlan.ta\n",
    "        sum_scount = {}\n",
    "        for level, threshold in CU_THRESHOLDS.items():\n",
    "            cu_filtered = filtered[filtered['wlan.qbss.cu'] > threshold]\n",
    "            # Drop duplicate wlan.ta, keep first (could use .max() if preferred)\n",
    "            unique_scount = cu_filtered.drop_duplicates('wlan.ta')\n",
    "            sum_scount[level] = unique_scount['wlan.qbss.scount'].sum()\n",
    "                # Count unique radios (wlan.ta) with ssid \"eduroam\"\n",
    "        eduroam_radios = filtered[filtered['wlan.ssid'] == 'eduroam']['wlan.ta'].nunique()\n",
    " \n",
    "    else:\n",
    "        max_scount = max_cu = avg_cu = median_cu = 0\n",
    "        duration = {'75': 0, '50': 0}\n",
    "        max_streak = {'75': 0, '50': 0}\n",
    "        sum_scount = {'75': 0, '50': 0}\n",
    "        eduroam_radios = 0\n",
    "\n",
    "    # Save values back to DataFrame\n",
    "    class_sessions_df.at[idx, 'max_stations'] = max_scount\n",
    "    class_sessions_df.at[idx, 'stations_enrolled'] = max_scount / session['enrolled'] if session['enrolled'] else 0\n",
    "    class_sessions_df.at[idx, 'max_cu'] = max_cu\n",
    "    class_sessions_df.at[idx, 'average_cu'] = avg_cu\n",
    "    class_sessions_df.at[idx, 'median_cu'] = median_cu\n",
    "    class_sessions_df.at[idx, 'number_beacons'] = number_beacons\n",
    "\n",
    "    class_sessions_df.at[idx, 'duration_75'] = duration['75']\n",
    "    class_sessions_df.at[idx, 'duration_50'] = duration['50']\n",
    "    class_sessions_df.at[idx, 'max_streak_75'] = max_streak['75']\n",
    "    class_sessions_df.at[idx, 'max_streak_50'] = max_streak['50']\n",
    "    class_sessions_df.at[idx, 'sum_scount_75'] = sum_scount['75']\n",
    "    class_sessions_df.at[idx, 'sum_scount_50'] = sum_scount['50']\n",
    "    class_sessions_df.at[idx, 'number_radios'] = eduroam_radios\n",
    "\n",
    "\n",
    "# Total number of class sessions\n",
    "total_sessions = len(class_sessions_df)\n",
    "\n",
    "# Count of sessions with CU > 50% (i.e., duration_50 > 0)\n",
    "sessions_over_50 = (class_sessions_df['duration_50'] > 0).sum()\n",
    "\n",
    "# Count of sessions with CU > 75% (i.e., duration_75 > 0)\n",
    "sessions_over_75 = (class_sessions_df['duration_75'] > 0).sum()\n",
    "\n",
    "# Percentages\n",
    "percent_over_50 = (sessions_over_50 / total_sessions) * 100\n",
    "percent_over_75 = (sessions_over_75 / total_sessions) * 100\n",
    "\n",
    "log_and_print(f\"Percentage of class sessions with at least 1s CU > 50%: {percent_over_50:.2f}%\")\n",
    "log_and_print(f\"Percentage of class sessions with at least 1s CU > 75%: {percent_over_75:.2f}%\")\n",
    "\n",
    "\n",
    "# Total durations\n",
    "total_duration_50 = class_sessions_df['duration_50'].sum()\n",
    "total_duration_75 = class_sessions_df['duration_75'].sum()\n",
    "total_duration_all = class_sessions_df['class_duration'].sum()\n",
    "\n",
    "# Total number of stations affected (from sum_scount columns)\n",
    "total_scount_50 = class_sessions_df['sum_scount_50'].sum()\n",
    "total_scount_75 = class_sessions_df['sum_scount_75'].sum()\n",
    "total_scount_all = class_sessions_df['max_stations'].sum()\n",
    "\n",
    "log_and_print(f\"Total duration all classes: {total_duration_all:.2f} seconds\")\n",
    "log_and_print(f\"Total class duration with CU > 50%: {total_duration_50:.2f} seconds ({total_duration_50 / total_duration_all * 100:.2f}%)\")\n",
    "log_and_print(f\"Total class duration with CU > 75%: {total_duration_75:.2f} seconds ({total_duration_75 / total_duration_all * 100:.2f}%)\")\n",
    "\n",
    "#this is probably not uesful because the same students/stations are in multiple classes\n",
    "log_and_print(f\"Total stations in all classes: {int(total_scount_all)}\")\n",
    "log_and_print(f\"Total stations affected (CU > 50%): {int(total_scount_50)} ({total_scount_50 / total_scount_all * 100:.2f}%)\")\n",
    "log_and_print(f\"Total stations affected (CU > 75%): {int(total_scount_75)} ({total_scount_75 / total_scount_all * 100:.2f}%)\")\n",
    "\n",
    "# For max_streak_50\n",
    "mean_streak_50 = class_sessions_df['max_streak_50'].mean()\n",
    "median_streak_50 = class_sessions_df['max_streak_50'].median()\n",
    "\n",
    "# For max_streak_75\n",
    "mean_streak_75 = class_sessions_df['max_streak_75'].mean()\n",
    "median_streak_75 = class_sessions_df['max_streak_75'].median()\n",
    "\n",
    "log_and_print(\"Duration of longest continuous channel utilization\")\n",
    "log_and_print(f\"CU > 50% - Mean Streak: {mean_streak_50:.2f} sec, Median Streak: {median_streak_50:.2f} sec\")\n",
    "log_and_print(f\"CU > 75% - Mean Streak: {mean_streak_75:.2f} sec, Median Streak: {median_streak_75:.2f} sec\")\n",
    "\n",
    "# histogram of max streak durations for each class session\n",
    "\n",
    "# Get the maximum value across both columns\n",
    "max_val = int(max(class_sessions_df['max_streak_50'].max(),\n",
    "                  class_sessions_df['max_streak_75'].max()))\n",
    "\n",
    "# Create bins from 0 to max_val with step 1\n",
    "bins = range(0, max_val + 2)  # +2 to include the last value in the bin range\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(class_sessions_df['max_streak_50'], bins=bins, alpha=0.6, label='CU > 50%')\n",
    "plt.hist(class_sessions_df['max_streak_75'], bins=bins, alpha=0.6, label='CU > 75%')\n",
    "\n",
    "#plt.xlim(0, 120)  # Adjust based on where most of your data falls\n",
    "plt.xlabel('Max Continuous High CU Duration (seconds)')\n",
    "plt.ylabel('Number of Class Sessions')\n",
    "plt.title('Max High CU Streaks (showing outliers)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plot_file = f\"{CLASS_SESSIONS_FOLDER}/High_CU_streaks.png\"\n",
    "#save to a file\n",
    "plt.savefig(plot_file)\n",
    "plt.show()\n",
    "\n",
    "#plot again zoomed in\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(class_sessions_df['max_streak_50'], bins=bins, alpha=0.6, label='CU > 50%')\n",
    "plt.hist(class_sessions_df['max_streak_75'], bins=bins, alpha=0.6, label='CU > 75%')\n",
    "plt.xlim(0, 60)  # Adjust based on where most of your data falls\n",
    "plt.xlabel('Max Continuous High CU Duration (seconds)')\n",
    "plt.ylabel('Number of Class Sessions')\n",
    "plt.title('Max High CU Streaks (zoomed in to 60 seconds)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_file = f\"{CLASS_SESSIONS_FOLDER}/High_CU_streaks_zoomed.png\"\n",
    "#save to a file\n",
    "plt.savefig(plot_file)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the total of max_stations and enrolled\n",
    "total_max_stations = class_sessions_df['max_stations'].sum()\n",
    "total_enrolled = class_sessions_df['enrolled'].sum()\n",
    "\n",
    "# Prevent division by zero\n",
    "if total_enrolled == 0:\n",
    "    average_devices_per_enrolled = 0\n",
    "else:\n",
    "    average_devices_per_enrolled = total_max_stations / total_enrolled\n",
    "\n",
    "log_and_print(f\"Average devices per enrolled: {average_devices_per_enrolled:.2f}\")\n",
    "\n",
    "# Distribution of Stations per enrolled\n",
    "class_sessions_df['stations_enrolled'].hist(bins=300)\n",
    "plt.title(\"Distribution of Stations per Enrolled\")\n",
    "plt.xlabel(\"Stations per Enrolled\")\n",
    "plt.ylabel(\"Frequency of Class Sessions\")\n",
    "plot_file = f\"{CLASS_SESSIONS_FOLDER}/stations_enrolled_histogram.png\"\n",
    "#save to a file\n",
    "plt.savefig(plot_file)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(class_sessions_df['enrolled'], class_sessions_df['max_stations'], alpha=0.5, edgecolors='k')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Enrolled\")\n",
    "plt.ylabel(\"Associated stations\")\n",
    "plt.title(\"Comparison of class enrollment to station count\")\n",
    "plt.grid(True)\n",
    "\n",
    "plot_file = f\"{CLASS_SESSIONS_FOLDER}/stations_enrolled_plot.png\"\n",
    "#save to a file\n",
    "plt.savefig(plot_file)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "log_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Beacon-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
